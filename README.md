# RAG-Project
Objective:
Build a small chatbot that answers questions based only on a provided document set.

Constraints:

Must not allow the LLM to answer from general knowledge (only from provided docs).
Must use an embedding-based retrieval step before generation.
Dataset should have at least 10+ documents.
Dataset Ideas:

Lecture notes (PDF â†’ text)
Wikipedia articles on a single topic
Product manuals
Steps:

Prepare your document set (convert to .txt or .md).
Use an embedding model (e.g., OpenAI text-embedding-ada-002 or sentence-transformers) to vectorize documents.
Store embeddings in a vector database (e.g., FAISS, ChromaDB).
On a query:
Convert question to embedding
Retrieve top relevant docs
Pass retrieved text to LLM with instruction:
Answer the question using only the provided context. 
If the answer is not in the context, say "I don't know."
Test with 5+ queries.
Resources:

FAISS Documentation
LangChain RAG Tutorial
Sentence Transformers
Deliverables for All Projects
Notebook or Python script with working code
README explaining setup, usage, and findings
Short report summarizing results and challenges
